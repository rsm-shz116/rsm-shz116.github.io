samples <- matrix(NA, nrow = n_iter, ncol = n_params)
current_lp <- log_post(beta, X, y)
for (i in 1:n_iter) {
proposal <- beta + rnorm(n_params, 0, proposal_sd)
proposal_lp <- log_post(proposal, X, y)
log_accept_ratio <- proposal_lp - current_lp
if (log(runif(1)) < log_accept_ratio) {
beta <- proposal
current_lp <- proposal_lp
}
samples[i, ] <- beta
}
samples[(burn_in + 1):n_iter, ]
}
# Run sampler
posterior_samples <- mh_sampler(X, y)
# Assign parameter names
colnames(posterior_samples) <- c("beta_netflix", "beta_prime", "beta_ads", "beta_price")
# Posterior summary
post_summary <- apply(posterior_samples, 2, function(x) {
c(mean = mean(x),
sd = sd(x),
lower_2.5 = quantile(x, 0.025),
upper_97.5 = quantile(x, 0.975))
})
# Clean output
bayesian_summary <- round(t(post_summary), 3)
colnames(bayesian_summary) <- c("mean", "sd", "lower.2.5%", "upper.97.5%")
print(bayesian_summary)
library(dplyr)
# Load the data
conjoint_data <- read.csv("conjoint_data.csv")
# Convert categorical variables
df <- conjoint_data %>%
mutate(
ad_yes = ifelse(ad == "Yes", 1, 0),
brand_N = ifelse(brand == "N", 1, 0),
brand_P = ifelse(brand == "P", 1, 0)
) %>%
select(choice, brand_N, brand_P, ad_yes, price)
library(dplyr)
# Load the data
conjoint_data <- read.csv("conjoint_data.csv")
# Convert categorical variables
df <- conjoint_data %>%
mutate(
ad_yes = ifelse(ad == "Yes", 1, 0),
brand_N = ifelse(brand == "N", 1, 0),
brand_P = ifelse(brand == "P", 1, 0)
)
X <- as.matrix(df[, c("brand_N", "brand_P", "ad_yes", "price")])
y <- df$choice
library(dplyr)
# Load the data
conjoint_data <- read.csv("conjoint_data.csv")
# Convert categorical variables
df <- conjoint_data %>%
mutate(
ad_yes = ifelse(ad == "Yes", 1, 0),
brand_N = ifelse(brand == "N", 1, 0),
brand_P = ifelse(brand == "P", 1, 0)
)
X <- as.matrix(df[, c("brand_N", "brand_P", "ad_yes", "price")])
y <- df$choice
df
# Log-likelihood
log_likelihood <- function(beta) {
lin_pred <- X %*% beta
-sum(y * lin_pred - log(1 + exp(lin_pred)))
}
# Estimate using optim
mle_result <- optim(
par = rep(0, 4),
fn = log_likelihood,
hessian = TRUE,
method = "BFGS"
)
mle_estimates <- mle_result$par
se <- sqrt(diag(solve(mle_result$hessian)))
ci <- cbind(
lower = mle_estimates - 1.96 * se,
estimate = mle_estimates,
upper = mle_estimates + 1.96 * se
)
colnames(ci) <- c("2.5%", "Estimate", "97.5%")
rownames(ci) <- c("brand_N", "brand_P", "ad_yes", "price")
round(ci, 3)
# Prior
log_prior <- function(beta) {
dnorm(beta[1], 0, sqrt(5), log = TRUE) +
dnorm(beta[2], 0, sqrt(5), log = TRUE) +
dnorm(beta[3], 0, sqrt(5), log = TRUE) +
dnorm(beta[4], 0, 1, log = TRUE)
}
# Posterior
log_posterior <- function(beta) {
-log_likelihood(beta) + log_prior(beta)
}
# MCMC sampler
run_mcmc <- function(start, n_iter = 11000) {
draws <- matrix(NA, nrow = n_iter, ncol = length(start))
colnames(draws) <- c("brand_N", "brand_P", "ad_yes", "price")
beta_current <- start
log_post_current <- log_posterior(beta_current)
for (i in 1:n_iter) {
proposal <- beta_current + c(
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.005))
)
log_post_proposal <- log_posterior(proposal)
log_accept_ratio <- log_post_proposal - log_post_current
if (log(runif(1)) < log_accept_ratio) {
beta_current <- proposal
log_post_current <- log_post_proposal
}
draws[i, ] <- beta_current
}
draws
}
set.seed(42)
posterior_draws <- run_mcmc(rep(0, 4))
posterior_draws <- posterior_draws[1001:11000, ]
posterior_draws
post_summary <- apply(posterior_draws, 2, function(x) {
c(mean = mean(x), sd = sd(x),
lower = quantile(x, 0.025),
upper = quantile(x, 0.975))
})
bayesian_summary <- round(t(post_summary), 3)
colnames(bayesian_summary) <- c("mean", "sd", "lower.2.5%", "upper.97.5%")
bayesian_summary
conjoint_data <- read.csv("conjoint_data.csv")
# Create dummy variables
conjoint_data$brand_N <- as.integer(conjoint_data$brand == "N")
conjoint_data$brand_P <- as.integer(conjoint_data$brand == "P")
conjoint_data$ad_Yes  <- as.integer(conjoint_data$ad == "Yes")
# Sort by respondent and task
conjoint_data <- conjoint_data[order(conjoint_data$resp, conjoint_data$task), ]
conjoint_data
log_likelihood <- function(beta, data) {
X <- as.matrix(data[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- data$choice
n <- nrow(data)
Xb <- X %*% beta
groups <- rep(1:(n / 3), each = 3)
log_lik <- tapply(1:n, groups, function(idx) {
xb <- Xb[idx]
chosen <- y[idx]
if (sum(chosen) != 1) return(NA)
# Log-sum-exp trick for numerical stability
max_xb <- max(xb)
denom <- max_xb + log(sum(exp(xb - max_xb)))
num <- xb[which(chosen == 1)]
return(num - denom)
})
total <- sum(unlist(log_lik), na.rm = TRUE)
if (is.na(total) || is.infinite(total)) return(1e6)
return(-total)
}
# -------------------------------------
# 3. Estimate MLE using optim()
# -------------------------------------
init_beta <- c(1, 0.5, -0.8, -0.1)
mle <- optim(
par = init_beta,
fn = log_likelihood,
data = conjoint_data,
method = "BFGS",
hessian = TRUE,
control = list(maxit = 1000)
)
# Check convergence
print(paste("Convergence code:", mle$convergence))  # 0 = success
# -------------------------------------
# 4. Compute standard errors and 95% CIs
# -------------------------------------
# Load MASS for ginv (in case Hessian is singular)
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
H <- mle$hessian
vcov_matrix <- tryCatch(solve(H), error = function(e) ginv(H))
se <- sqrt(diag(vcov_matrix))
# Confidence intervals
z <- qnorm(0.975)
lower <- mle$par - z * se
upper <- mle$par + z * se
# -------------------------------------
# 5. Format and display results
# -------------------------------------
mle_results <- data.frame(
Parameter = c("beta_netflix", "beta_prime", "beta_ads", "beta_price"),
Estimate = round(mle$par, 4),
Std_Error = round(se, 4),
CI_Lower = round(lower, 4),
CI_Upper = round(upper, 4)
)
print(mle_results)
log_likelihood <- function(beta, data) {
X <- as.matrix(data[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- data$choice
n <- nrow(data)
Xb <- X %*% beta
groups <- rep(1:(n / 3), each = 3)
log_lik <- tapply(1:n, groups, function(idx) {
xb <- Xb[idx]
chosen <- y[idx]
if (sum(chosen) != 1) return(NA)
# Log-sum-exp trick for numerical stability
max_xb <- max(xb)
denom <- max_xb + log(sum(exp(xb - max_xb)))
num <- xb[which(chosen == 1)]
return(num - denom)
})
total <- sum(unlist(log_lik), na.rm = TRUE)
if (is.na(total) || is.infinite(total)) return(1e6)
return(-total)
}
# -------------------------------------
# 3. Estimate MLE using optim()
# -------------------------------------
init_beta <- c(1, 0.5, -0.8, -0.1)
mle <- optim(
par = init_beta,
fn = log_likelihood,
data = conjoint_data,
method = "BFGS",
hessian = TRUE,
control = list(maxit = 1000)
)
# Check convergence
print(paste("Convergence code:", mle$convergence))  # 0 = success
# -------------------------------------
# 4. Compute standard errors and 95% CIs
# -------------------------------------
# Load MASS for ginv (in case Hessian is singular)
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
H <- mle$hessian
vcov_matrix <- tryCatch(solve(H), error = function(e) ginv(H))
se <- sqrt(diag(vcov_matrix))
# Confidence intervals
z <- qnorm(0.975)
lower <- mle$par - z * se
upper <- mle$par + z * se
# -------------------------------------
# 5. Format and display results
# -------------------------------------
mle_results <- data.frame(
Parameter = c("beta_netflix", "beta_prime", "beta_ads", "beta_price"),
Estimate = round(mle$par, 4),
Std_Error = round(se, 4),
CI_Lower = round(lower, 4),
CI_Upper = round(upper, 4)
)
print(mle_results)
log_prior <- function(beta) {
sum(dnorm(beta[1:3], mean = 0, sd = sqrt(5), log = TRUE)) +
dnorm(beta[4], mean = 0, sd = 1, log = TRUE)
}
log_posterior <- function(beta, data) {
log_likelihood(beta, data) + log_prior(beta)
}
set.seed(123)
n_iter <- 11000
burn_in <- 1000
n_params <- 4
beta_samples <- matrix(NA, nrow = n_iter, ncol = n_params)
colnames(beta_samples) <- c("beta_netflix", "beta_prime", "beta_ads", "beta_price")
beta_current <- c(1, 0.5, -0.8, -0.1)
log_post_current <- log_posterior(beta_current, conjoint_data)
proposal_sds <- c(0.05, 0.05, 0.05, 0.005)
for (s in 1:n_iter) {
beta_proposal <- rnorm(n_params, mean = beta_current, sd = proposal_sds)
log_post_proposal <- log_posterior(beta_proposal, conjoint_data)
if (log(runif(1)) < (log_post_proposal - log_post_current)) {
beta_current <- beta_proposal
log_post_current <- log_post_proposal
}
beta_samples[s, ] <- beta_current
}
posterior_samples <- beta_samples[(burn_in + 1):n_iter, ]
posterior_summary <- apply(posterior_samples, 2, function(x) {
c(mean = mean(x),
sd = sd(x),
CI_2.5 = quantile(x, 0.025),
CI_97.5 = quantile(x, 0.975))
})
print(round(t(posterior_summary), 4))
log_prior <- function(beta) {
sum(dnorm(beta[1:3], mean = 0, sd = sqrt(5), log = TRUE)) +
dnorm(beta[4], mean = 0, sd = 1, log = TRUE)
}
log_posterior <- function(beta, data) {
log_likelihood(beta, data) + log_prior(beta)
}
set.seed(42)
n_iter <- 11000
burn_in <- 1000
n_params <- 4
beta_samples <- matrix(NA, nrow = n_iter, ncol = n_params)
colnames(beta_samples) <- c("beta_netflix", "beta_prime", "beta_ads", "beta_price")
beta_current <- c(1, 0.5, -0.8, -0.1)
log_post_current <- log_posterior(beta_current, conjoint_data)
proposal_sds <- c(0.05, 0.05, 0.05, 0.005)
for (s in 1:n_iter) {
beta_proposal <- rnorm(n_params, mean = beta_current, sd = proposal_sds)
log_post_proposal <- log_posterior(beta_proposal, conjoint_data)
if (log(runif(1)) < (log_post_proposal - log_post_current)) {
beta_current <- beta_proposal
log_post_current <- log_post_proposal
}
beta_samples[s, ] <- beta_current
}
log_prior <- function(beta) {
dnorm(beta[1], 0, sqrt(5), log = TRUE) +  # brand_Netflix
dnorm(beta[2], 0, sqrt(5), log = TRUE) +  # brand_Prime
dnorm(beta[3], 0, sqrt(5), log = TRUE) +  # ad_included
dnorm(beta[4], 0, 1, log = TRUE)          # price
}
# Log posterior function (likelihood + prior)
log_posterior <- function(beta) {
-log_likelihood(beta) + log_prior(beta)
}
run_mcmc <- function(start, n_iter = 11000) {
draws <- matrix(NA, nrow = n_iter, ncol = length(start))
colnames(draws) <- c("brand_N", "brand_P", "ad_yes", "price")
beta_current <- start
log_post_current <- log_posterior(beta_current)
for (i in 1:n_iter) {
proposal <- beta_current + c(
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.005))
)
log_post_proposal <- log_posterior(proposal)
log_accept_ratio <- log_post_proposal - log_post_current
if (log(runif(1)) < log_accept_ratio) {
beta_current <- proposal
log_post_current <- log_post_proposal
}
draws[i, ] <- beta_current
}
return(draws)
}
# Run MCMC
set.seed(42)
posterior_draws <- run_mcmc(start = rep(0, 4))
conjoint_data <- read.csv("conjoint_data.csv")
# Create dummy variables
conjoint_data$brand_N <- as.integer(conjoint_data$brand == "N")
conjoint_data$brand_P <- as.integer(conjoint_data$brand == "P")
conjoint_data$ad_Yes  <- as.integer(conjoint_data$ad == "Yes")
# Sort by respondent and task
conjoint_data <- conjoint_data[order(conjoint_data$resp, conjoint_data$task), ]
conjoint_data
conjoint_data
log_likelihood <- function(beta, conjoint_data) {
X <- as.matrix(conjoint_data[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- conjoint_data$choice
n <- nrow(conjoint_data)
Xb <- X %*% beta
groups <- rep(1:(n / 3), each = 3)
log_lik <- tapply(1:n, groups, function(idx) {
xb <- Xb[idx]
chosen <- y[idx]
if (sum(chosen) != 1) return(NA)
# Log-sum-exp trick for numerical stability
max_xb <- max(xb)
denom <- max_xb + log(sum(exp(xb - max_xb)))
num <- xb[which(chosen == 1)]
return(num - denom)
})
total <- sum(unlist(log_lik), na.rm = TRUE)
if (is.na(total) || is.infinite(total)) return(1e6)
return(-total)
}
# -------------------------------------
# 3. Estimate MLE using optim()
# -------------------------------------
init_beta <- c(1, 0.5, -0.8, -0.1)
mle <- optim(
par = init_beta,
fn = log_likelihood,
data = conjoint_data,
method = "BFGS",
hessian = TRUE,
control = list(maxit = 1000)
)
log_likelihood <- function(beta, data) {
X <- as.matrix(conjoint_data[, c("brand_N", "brand_P", "ad_Yes", "price")])
y <- conjoint_data$choice
n <- nrow(conjoint_data)
Xb <- X %*% beta
groups <- rep(1:(n / 3), each = 3)
log_lik <- tapply(1:n, groups, function(idx) {
xb <- Xb[idx]
chosen <- y[idx]
if (sum(chosen) != 1) return(NA)
# Log-sum-exp trick for numerical stability
max_xb <- max(xb)
denom <- max_xb + log(sum(exp(xb - max_xb)))
num <- xb[which(chosen == 1)]
return(num - denom)
})
total <- sum(unlist(log_lik), na.rm = TRUE)
if (is.na(total) || is.infinite(total)) return(1e6)
return(-total)
}
# -------------------------------------
# 3. Estimate MLE using optim()
# -------------------------------------
init_beta <- c(1, 0.5, -0.8, -0.1)
mle <- optim(
par = init_beta,
fn = log_likelihood,
data = conjoint_data,
method = "BFGS",
hessian = TRUE,
control = list(maxit = 1000)
)
# Check convergence
print(paste("Convergence code:", mle$convergence))  # 0 = success
# -------------------------------------
# 4. Compute standard errors and 95% CIs
# -------------------------------------
# Load MASS for ginv (in case Hessian is singular)
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
H <- mle$hessian
vcov_matrix <- tryCatch(solve(H), error = function(e) ginv(H))
se <- sqrt(diag(vcov_matrix))
# Confidence intervals
z <- qnorm(0.975)
lower <- mle$par - z * se
upper <- mle$par + z * se
# -------------------------------------
# 5. Format and display results
# -------------------------------------
mle_results <- data.frame(
Parameter = c("beta_netflix", "beta_prime", "beta_ads", "beta_price"),
Estimate = round(mle$par, 4),
Std_Error = round(se, 4),
CI_Lower = round(lower, 4),
CI_Upper = round(upper, 4)
)
print(mle_results)
log_prior <- function(beta) {
dnorm(beta[1], 0, sqrt(5), log = TRUE) +  # brand_Netflix
dnorm(beta[2], 0, sqrt(5), log = TRUE) +  # brand_Prime
dnorm(beta[3], 0, sqrt(5), log = TRUE) +  # ad_included
dnorm(beta[4], 0, 1, log = TRUE)          # price
}
# Log posterior function (likelihood + prior)
log_posterior <- function(beta) {
-log_likelihood(beta) + log_prior(beta)
}
run_mcmc <- function(start, n_iter = 11000) {
draws <- matrix(NA, nrow = n_iter, ncol = length(start))
colnames(draws) <- c("brand_N", "brand_P", "ad_yes", "price")
beta_current <- start
log_post_current <- log_posterior(beta_current)
for (i in 1:n_iter) {
proposal <- beta_current + c(
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.05)),
rnorm(1, 0, sqrt(0.005))
)
log_post_proposal <- log_posterior(proposal)
log_accept_ratio <- log_post_proposal - log_post_current
if (log(runif(1)) < log_accept_ratio) {
beta_current <- proposal
log_post_current <- log_post_proposal
}
draws[i, ] <- beta_current
}
return(draws)
}
# Run MCMC
set.seed(42)
posterior_draws <- run_mcmc(start = rep(0, 4))
# Drop first 1000 as burn-in
posterior_draws <- posterior_draws[1001:11000, ]
# Summarize results
post_summary <- apply(posterior_draws, 2, function(x) {
c(mean = mean(x), sd = sd(x),
lower = quantile(x, 0.025),
upper = quantile(x, 0.975))
})
round(t(post_summary), 3)
beta_price_samples <- posterior_samples[, "beta_price"]
par(mfrow = c(1, 2))
plot(posterior_draws[, "ad_yes"], type = "l",
main = "Trace Plot: Beta_Price",
xlab = "Iteration", ylab = "Value")
hist(posterior_draws[, "ad_yes"], breaks = 40, col = "lightblue", border = "white",
main = "Posterior of Beta_Price",
xlab = "Value", probability = TRUE)
abline(v = mean(posterior_draws), col = "red", lwd = 2)
par(mfrow = c(1, 2))
plot(posterior_draws[, "brand_P"], type = "l",
main = "Trace Plot: Beta_Price",
xlab = "Iteration", ylab = "Value")
hist(posterior_draws[, "brand_P"], breaks = 40, col = "lightblue", border = "white",
main = "Posterior of Beta_Price",
xlab = "Value", probability = TRUE)
abline(v = mean(posterior_draws), col = "red", lwd = 2)
post_summary
print(mle_results)
